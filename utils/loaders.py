# utils/loaders.py v5.1 ROBUST PARSING
import json
import os
from typing import List, Dict, Any, Optional, Tuple

def load_intents(filepath: str, max_lines: Optional[int] = None) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω—Ç–µ–Ω—Ç—ã –∏–∑ JSONL –∏–ª–∏ JSON —Å ROBUST –ø–∞—Ä—Å–∏–Ω–≥–æ–º"""
    from .config import MAX_LINES, FILTER_EXPIRED
    from .version_manager import filter_expired_intents, get_version_statistics
    
    if max_lines is None:
        max_lines = MAX_LINES if MAX_LINES > 0 else 1000000
    
    if not os.path.exists(filepath):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
        return [], {}
    
    file_size = os.path.getsize(filepath)
    print(f"üìÇ Loading data from: {filepath}")
    print(f"   Size: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
    
    intents = []
    total_lines = 0
    errors = {
        'empty': 0,
        'fixed': 0,
        'skipped': 0,
        'success': 0
    }
    
    # ========================================================================
    # –ü–û–ü–´–¢–ö–ê 1: JSON –º–∞—Å—Å–∏–≤ (–≤–µ—Å—å —Ñ–∞–π–ª —Ü–µ–ª–∏–∫–æ–º)
    # ========================================================================
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        if isinstance(data, list):
            print(f"‚úÖ Loaded as JSON array: {len(data)} records")
            intents = data[:max_lines]
            errors['success'] = len(intents)
        elif isinstance(data, dict):
            if 'intents' in data:
                print(f"‚úÖ Loaded from 'intents' key: {len(data['intents'])} records")
                intents = data['intents'][:max_lines]
                errors['success'] = len(intents)
            else:
                print(f"‚úÖ Loaded single dict as 1 record")
                intents = [data]
                errors['success'] = 1
                
        # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∑–∏–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
        if intents:
            metadata = _build_metadata(filepath, intents, errors, total_lines)
            return _apply_filters(intents, metadata)
            
    except json.JSONDecodeError:
        pass  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –º–µ—Ç–æ–¥
    except Exception as e:
        print(f"‚ö†Ô∏è  Attempt 1 (JSON array) failed: {e}")
    
    # ========================================================================
    # –ü–û–ü–´–¢–ö–ê 2: JSONL –ø–æ—Å—Ç—Ä–æ—á–Ω–æ —Å ROBUST –ø–∞—Ä—Å–∏–Ω–≥–æ–º
    # ========================================================================
    try:
        print("üìñ Trying JSONL line-by-line with robust parsing...")
        intents = []
        
        with open(filepath, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                total_lines += 1
                line = line.strip()
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                if not line or line.startswith('#') or line.startswith('//'):
                    errors['empty'] += 1
                    continue
                
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                try:
                    obj = json.loads(line)
                    if isinstance(obj, dict):
                        intents.append(obj)
                        errors['success'] += 1
                    continue
                    
                except json.JSONDecodeError as e:
                    # ROBUST: –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–µ—Ä–µ–∑ raw_decode (Extra data)
                    try:
                        decoder = json.JSONDecoder()
                        remaining = line
                        extracted = False
                        
                        while remaining:
                            remaining = remaining.strip()
                            if not remaining:
                                break
                            
                            try:
                                obj, idx = decoder.raw_decode(remaining)
                                if isinstance(obj, dict):
                                    intents.append(obj)
                                    errors['fixed'] += 1
                                    extracted = True
                                remaining = remaining[idx:]
                            except Exception:
                                break
                        
                        if not extracted:
                            # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                            if errors['skipped'] < 10:
                                print(f"‚ö†Ô∏è  Line {line_num}: JSON decode error - {str(e)}")
                            errors['skipped'] += 1
                            
                    except Exception:
                        if errors['skipped'] < 10:
                            print(f"‚ö†Ô∏è  Line {line_num}: JSON decode error - {str(e)}")
                        errors['skipped'] += 1
                
                # –ó–∞—â–∏—Ç–∞ –æ—Ç –æ–≥—Ä–æ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                if len(intents) >= max_lines:
                    print(f"‚ö†Ô∏è  Reached max_lines limit: {max_lines}")
                    break
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if intents:
            print(f"‚úÖ Successfully loaded: {errors['success']} records")
            if errors['fixed'] > 0:
                print(f"üîß Fixed (Extra data): {errors['fixed']} records")
            if errors['empty'] > 0:
                print(f"‚ö™ Skipped (empty/comments): {errors['empty']} lines")
            if errors['skipped'] > 0:
                print(f"‚ö†Ô∏è  Skipped (invalid JSON): {errors['skipped']} lines")
            if errors['skipped'] > 10:
                print(f"   (showing first 10 errors only)")
            print(f"üìù Total lines processed: {total_lines}")
            
            metadata = _build_metadata(filepath, intents, errors, total_lines)
            return _apply_filters(intents, metadata)
        else:
            print(f"‚ùå Could not load any valid JSON objects")
            print(f"üìù Lines processed: {total_lines}")
            print(f"‚ö†Ô∏è  Skipped: {errors['skipped']}")
            return [], {}
            
    except Exception as e:
        print(f"‚ùå Error loading file: {e}")
        return [], {}

def _build_metadata(filepath: str, intents: List[Dict], errors: Dict, total_lines: int) -> Dict:
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–∫–∏"""
    return {
        'source_file': filepath,
        'total_loaded': len(intents),
        'total_lines_processed': total_lines,
        'parsing_stats': {
            'success': errors['success'],
            'fixed_extra_data': errors['fixed'],
            'skipped_empty': errors['empty'],
            'skipped_invalid': errors['skipped']
        }
    }

def _apply_filters(intents: List[Dict], metadata: Dict) -> Tuple[List[Dict], Dict]:
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ (expired –∏ —Ç.–¥.)"""
    from .config import FILTER_EXPIRED
    from .version_manager import filter_expired_intents, get_version_statistics
    
    if FILTER_EXPIRED:
        active_intents, expired_count = filter_expired_intents(intents)
        if expired_count > 0:
            print(f"‚ö†Ô∏è  Filtered expired: {expired_count} records")
            metadata['filtered_expired'] = expired_count
        intents = active_intents
    
    metadata['final_count'] = len(intents)
    metadata['version_statistics'] = get_version_statistics(intents)
    
    return intents, metadata
