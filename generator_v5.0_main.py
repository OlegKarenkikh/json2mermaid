#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dialog Analyzer v5.1
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ —Å –ø–æ–ª–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –∞–Ω–∞–ª–∏–∑–æ–º –≥—Ä–∞—Ñ–∞
"""

import os
import sys

from utils.config import *
from utils.loaders import load_intents
from utils.validators import run_all_validations, save_validation_report
from utils.analyzers import first_pass, second_pass, third_pass, fourth_pass

# Import new graph analyzer
try:
    from utils.graph_analyzer import analyze_graph_structure
    GRAPH_ANALYSIS_AVAILABLE = True
except ImportError:
    GRAPH_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è  Graph analysis module not available")

def print_section(title: str, width: int = 80):
    """Print formatted section header"""
    print("\n" + "="*width)
    print(title)
    print("="*width)

def main():
    """Main analyzer function"""
    print_section("üöÄ DIALOG ANALYZER v5.1")
    print()
    
    # Check input file
    if not os.path.exists(INPUT_FILE):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_FILE}")
        print(f"üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª intent_data.jsonl —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–Ω—Ç–µ–Ω—Ç–æ–≤")
        return 1
    
    # 1. Load data
    print_section("üìÖ –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    intents, metadata = load_intents(INPUT_FILE, MAX_LINES)
    
    if not intents:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return 1
    
    print(f"\nüìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {metadata.get('total_loaded', 0)}")
    print(f"   –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {metadata.get('final_count', 0)}")
    
    if 'filtered_expired' in metadata:
        print(f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –∏—Å—Ç—ë–∫—à–∏—Ö: {metadata['filtered_expired']}")
    
    version_stats = metadata.get('version_statistics', {})
    if version_stats:
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä—Å–∏–π:")
        print(f"   –° –≤–µ—Ä—Å–∏–µ–π: {version_stats.get('with_version', 0)}")
        print(f"   –° expire: {version_stats.get('with_expire', 0)}")
        print(f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö: {version_stats.get('active', 0)}")
        print(f"   –ò—Å—Ç—ë–∫—à–∏—Ö: {version_stats.get('expired', 0)}")
    
    # 2. Validation
    if ENABLE_VALIDATION:
        print_section("üîç –≠–¢–ê–ü 2: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
        validation_results = run_all_validations(intents, {})
        
        if STOP_ON_VALIDATION_ERRORS and not validation_results['summary']['is_valid']:
            print("\n‚ùå –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return 1
        
        # Save validation report
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        save_validation_report(validation_results, OUTPUT_DIR)
    
    # 3. Analysis (4 passes)
    print_section("üî¨ –≠–¢–ê–ü 3: –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (4 –ø—Ä–æ—Ö–æ–¥–∞)")
    all_data = first_pass(intents)
    all_data = second_pass(intents, all_data)
    all_data = third_pass(intents, all_data)
    all_data = fourth_pass(intents, all_data)
    
    # 4. Graph structure analysis
    if GRAPH_ANALYSIS_AVAILABLE and ENABLE_VALIDATION:
        redirect_map = validation_results.get('redirects', {}).get('redirect_map', {})
        graph_analysis = analyze_graph_structure(intents, redirect_map)
        all_data['graph_analysis'] = graph_analysis
    
    # 5. Statistics
    print_section("üìä –≠–¢–ê–ü 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    print(f"   –í—Å–µ–≥–æ –∏–Ω—Ç–µ–Ω—Ç–æ–≤: {len(intents)}")
    print(f"   –ü–µ—Ä–µ—Ö–æ–¥–æ–≤: {len(all_data.get('transitions', []))}")
    
    # Count by types
    type_counts = {}
    for intent_id, classification in all_data['classifications'].items():
        intent_type = classification.intent_type
        type_counts[intent_type] = type_counts.get(intent_type, 0) + 1
    
    print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
    for intent_type, count in sorted(type_counts.items(), key=lambda x: -x[1]):
        print(f"      {intent_type}: {count}")
    
    # Count by subtypes
    if CLASSIFY_SUBTYPES:
        subtype_counts = {}
        for intent_id, classification in all_data['classifications'].items():
            if classification.subtype:
                subtype_counts[classification.subtype] = subtype_counts.get(classification.subtype, 0) + 1
        
        if subtype_counts:
            print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–æ–¥—Ç–∏–ø–∞–º:")
            for subtype, count in sorted(subtype_counts.items(), key=lambda x: -x[1]):
                print(f"      {subtype}: {count}")
    
    # Final message
    print_section("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!")
    print()
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {OUTPUT_DIR}/")
    
    if ENABLE_VALIDATION:
        print(f"üìÑ –û—Ç—á—ë—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {OUTPUT_DIR}/validation_report.json")
        
        summary = validation_results.get('summary', {})
        if summary.get('error_count', 0) > 0:
            print(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ—à–∏–±–æ–∫: {summary['error_count']}")
            print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ validation_report.json –¥–ª—è –¥–µ—Ç–∞–ª–µ–π")
        
        if summary.get('has_warnings', False):
            print(f"üí° –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {summary.get('warning_count', 0)}")
    
    print()
    print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –ø–æ—Ç–æ–∫–æ–≤")
    print()
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
