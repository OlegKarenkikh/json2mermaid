#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dialog Analyzer v5.1 - Risk-Aware + Quality Metrics Edition
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ä–∏—Å–∫–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞

–ü—Ä–∏–Ω—Ü–∏–ø—ã:
- –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ "–∫–∞–∫ –µ—Å—Ç—å" (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
- –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã —Ü–≤–µ—Ç–æ–º
- –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º —Ä–∏—Å–∫–∏, –Ω–æ –Ω–µ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º
- –°–æ—Ö—Ä–∞–Ω—è–µ–º audit trail –¥–ª—è —Ä—É—á–Ω–æ–≥–æ review
- –ò–∑–º–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import json

from utils.config import *
from utils.loaders import load_intents
from utils.validators import run_all_validations, save_validation_report
from utils.analyzers import first_pass, second_pass, third_pass, fourth_pass

# Import graph analyzer
try:
    from utils.graph_analyzer import analyze_graph_structure
    GRAPH_ANALYSIS_AVAILABLE = True
except ImportError:
    GRAPH_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è  Graph analysis module not available")

# Import risk analyzer
try:
    from utils.risk_analyzer import (
        analyze_intent_risks, generate_risk_summary, 
        generate_risk_legend, export_risk_report
    )
    RISK_ANALYSIS_AVAILABLE = True
except ImportError:
    RISK_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è  Risk analysis module not available")

# Import quality analyzers (NEW!)
try:
    from utils.regex_analyzer import analyze_intent_regex_patterns
    REGEX_ANALYSIS_AVAILABLE = True
except ImportError:
    REGEX_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è  Regex analysis module not available")

try:
    from utils.entry_point_analyzer import analyze_entry_points
    ENTRY_POINT_ANALYSIS_AVAILABLE = True
except ImportError:
    ENTRY_POINT_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è  Entry point analysis module not available")

try:
    from utils.freshness_analyzer import analyze_data_freshness, get_update_distribution
    FRESHNESS_ANALYSIS_AVAILABLE = True
except ImportError:
    FRESHNESS_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è  Freshness analysis module not available")

try:
    from utils.diagram_exporter import export_mermaid_graph
    DIAGRAM_EXPORT_AVAILABLE = True
except ImportError:
    DIAGRAM_EXPORT_AVAILABLE = False
    print("‚ö†Ô∏è  Diagram export module not available")

def print_section(title: str, width: int = 80):
    """Print formatted section header"""
    print("\n" + "="*width)
    print(title)
    print("="*width)

def main():
    """Main analyzer function"""
    print_section("üöÄ DIALOG ANALYZER v5.1 - QUALITY METRICS EDITION")
    print("üìú –†–µ–∂–∏–º: Read-Only Analysis with Quality Metrics")
    print("üõ°Ô∏è  –î–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω—è—é—Ç—Å—è - —Ç–æ–ª—å–∫–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –º–µ—Ç—Ä–∏–∫–∏")
    print("üìä –ù–û–í–û–ï: –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ production-ready –¥–∞–Ω–Ω—ã—Ö")
    print()
    
    # Check input file
    if not os.path.exists(INPUT_FILE):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_FILE}")
        print(f"üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª intent_data.jsonl —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–Ω—Ç–µ–Ω—Ç–æ–≤")
        return 1
    
    # 1. Load data
    print_section("üìÖ –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    intents, metadata = load_intents(INPUT_FILE, MAX_LINES)
    
    if not intents:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return 1
    
    print(f"\nüìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {metadata.get('total_loaded', 0)}")
    print(f"   –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {metadata.get('final_count', 0)}")
    
    if 'filtered_expired' in metadata:
        print(f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –∏—Å—Ç—ë–∫—à–∏—Ö: {metadata['filtered_expired']}")
    
    version_stats = metadata.get('version_statistics', {})
    if version_stats:
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä—Å–∏–π:")
        print(f"   –° –≤–µ—Ä—Å–∏–µ–π: {version_stats.get('with_version', 0)}")
        print(f"   –° expire: {version_stats.get('with_expire', 0)}")
        print(f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö: {version_stats.get('active', 0)}")
        print(f"   –ò—Å—Ç—ë–∫—à–∏—Ö: {version_stats.get('expired', 0)}")
    
    # 2. Validation
    validation_results = {}
    if ENABLE_VALIDATION:
        print_section("üîç –≠–¢–ê–ü 2: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
        validation_results = run_all_validations(intents, {})
        
        if STOP_ON_VALIDATION_ERRORS and not validation_results['summary']['is_valid']:
            print("\n‚ùå –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return 1
        
        # Save validation report
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        save_validation_report(validation_results, OUTPUT_DIR)
    
    # 3. Analysis (4 passes)
    print_section("üî¨ –≠–¢–ê–ü 3: –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (4 –ø—Ä–æ—Ö–æ–¥–∞)")
    all_data = first_pass(intents)
    all_data = second_pass(intents, all_data)
    all_data = third_pass(intents, all_data)
    all_data = fourth_pass(intents, all_data)
    transitions = [(t.source_id, t.target_id) for t in all_data.get('transitions', [])]
    
    # 4. Graph structure analysis
    if GRAPH_ANALYSIS_AVAILABLE and ENABLE_VALIDATION:
        redirect_map = validation_results.get('redirects', {}).get('redirect_map', {})
        graph_analysis = analyze_graph_structure(intents, redirect_map, transitions)
        all_data['graph_analysis'] = graph_analysis
        validation_results['graph_analysis'] = graph_analysis
    
    # 5. Quality Metrics Analysis (NEW!)
    quality_metrics = {}
    print_section("üìä –≠–¢–ê–ü 4: –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    # 5.1 Regex complexity
    if REGEX_ANALYSIS_AVAILABLE:
        regex_analysis = analyze_intent_regex_patterns(intents)
        quality_metrics['regex_complexity'] = regex_analysis
    
    # 5.2 Entry point diversity
    if ENTRY_POINT_ANALYSIS_AVAILABLE:
        entry_point_analysis = analyze_entry_points(intents)
        quality_metrics['entry_points'] = entry_point_analysis
    
    # 5.3 Data freshness
    if FRESHNESS_ANALYSIS_AVAILABLE:
        freshness_analysis = analyze_data_freshness(intents)
        if freshness_analysis['has_version_data']:
            update_dist = get_update_distribution(intents)
            freshness_analysis['update_distribution'] = update_dist
        quality_metrics['data_freshness'] = freshness_analysis
    
    # 6. Risk Analysis
    if RISK_ANALYSIS_AVAILABLE and ENABLE_VALIDATION:
        print_section("üõ°Ô∏è  –≠–¢–ê–ü 5: –ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤")
        
        # Analyze risks
        intent_risks = analyze_intent_risks(intents, validation_results)
        risk_summary = generate_risk_summary(intent_risks)
        
        # Display risk score
        risk_score = risk_summary['risk_score']
        if risk_score >= 80:
            score_icon = "‚úÖ"
        elif risk_score >= 60:
            score_icon = "üü°"
        elif risk_score >= 40:
            score_icon = "üü†"
        else:
            score_icon = "üî¥"
        
        print(f"\n{score_icon} –û–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥ —Ä–∏—Å–∫–æ–≤: {risk_score}/100")
        
        # Display severity distribution
        print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º —Ä–∏—Å–∫–∞:")
        severity_dist = risk_summary['severity_distribution']
        for severity in ['critical', 'high', 'medium', 'low', 'info']:
            count = severity_dist.get(severity, 0)
            if count > 0:
                pct = round(count / risk_summary['total_intents'] * 100, 1)
                print(f"   {severity.upper():10s}: {count:4d} ({pct}%)")
        
        # Show critical intents
        critical_intents = risk_summary['critical_intents']
        if critical_intents:
            print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–ù–¢–ï–ù–¢–´ ({len(critical_intents)}):")
            for intent_id in critical_intents[:5]:
                risk_obj = intent_risks[intent_id]
                print(f"   - {intent_id}")
                for risk_type, desc in risk_obj.risks[:2]:
                    print(f"      ‚Ä¢ {desc}")
            if len(critical_intents) > 5:
                print(f"   ... –∏ –µ—â—ë {len(critical_intents) - 5}")
        
        # Display risk legend
        print(generate_risk_legend())
        
        # Export comprehensive report with quality metrics
        risk_report_path = os.path.join(OUTPUT_DIR, 'risk_analysis.json')
        export_risk_report(intent_risks, risk_report_path)
        
        # Add quality metrics to report
        if quality_metrics:
            with open(risk_report_path, 'r', encoding='utf-8') as f:
                report = json.load(f)
            report['quality_metrics'] = quality_metrics
            with open(risk_report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –æ—Ç—á—ë—Ç")
        
        # Store in all_data for diagram generation
        all_data['intent_risks'] = intent_risks
        all_data['quality_metrics'] = quality_metrics

    # 6.1 Diagram export (Mermaid)
    if EXPORT_DIAGRAMS and DIAGRAM_EXPORT_AVAILABLE:
        diagram_path = os.path.join(OUTPUT_DIR, "graph.mmd")
        export_mermaid_graph(
            intents=intents,
            transitions=transitions,
            intent_risks=all_data.get('intent_risks'),
            output_path=diagram_path,
            include_legend=INCLUDE_LEGEND,
        )
        print(f"\nüñºÔ∏è  –î–∏–∞–≥—Ä–∞–º–º–∞ Mermaid —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {diagram_path}")
    
    # 7. Statistics
    print_section("üìä –≠–¢–ê–ü 6: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    print(f"   –í—Å–µ–≥–æ –∏–Ω—Ç–µ–Ω—Ç–æ–≤: {len(intents)}")
    print(f"   –ü–µ—Ä–µ—Ö–æ–¥–æ–≤: {len(all_data.get('transitions', []))}")
    
    # Count by types
    type_counts = {}
    for intent_id, classification in all_data['classifications'].items():
        intent_type = classification.intent_type
        type_counts[intent_type] = type_counts.get(intent_type, 0) + 1
    
    print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
    for intent_type, count in sorted(type_counts.items(), key=lambda x: -x[1]):
        print(f"      {intent_type}: {count}")
    
    # Count by subtypes
    if CLASSIFY_SUBTYPES:
        subtype_counts = {}
        for intent_id, classification in all_data['classifications'].items():
            if classification.subtype:
                subtype_counts[classification.subtype] = subtype_counts.get(classification.subtype, 0) + 1
        
        if subtype_counts:
            print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–æ–¥—Ç–∏–ø–∞–º:")
            for subtype, count in sorted(subtype_counts.items(), key=lambda x: -x[1]):
                print(f"      {subtype}: {count}")
    
    # Final message
    print_section("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!")
    print()
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {OUTPUT_DIR}/")
    print(f"   ‚Ä¢ validation_report.json - –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
    
    if RISK_ANALYSIS_AVAILABLE:
        print(f"   ‚Ä¢ risk_analysis.json - –∞–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ + –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
    
    if ENABLE_VALIDATION:
        summary = validation_results.get('summary', {})
        if summary.get('error_count', 0) > 0:
            print(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ—à–∏–±–æ–∫: {summary['error_count']}")
            print("   üëâ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ validation_report.json –¥–ª—è –¥–µ—Ç–∞–ª–µ–π")
        
        if summary.get('has_warnings', False):
            print(f"üí° –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {summary.get('warning_count', 0)}")
    
    print()
    print("üîç –í–ê–ñ–ù–û: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ù–ï –ë–´–õ–ò –ò–ó–ú–ï–ù–ï–ù–´")
    print("üé® –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —É–∑–ª—ã –±—É–¥—É—Ç –ø–æ–¥—Å–≤–µ—á–µ–Ω—ã –Ω–∞ –¥–∏–∞–≥—Ä–∞–º–º–∞—Ö")
    print("üìä –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ risk_analysis.json –¥–ª—è —Ä—É—á–Ω–æ–≥–æ review")
    print("‚ú® –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ —Ç–æ–º –∂–µ –æ—Ç—á—ë—Ç–µ")
    print()
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
